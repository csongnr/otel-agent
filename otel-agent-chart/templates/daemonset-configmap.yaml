apiVersion: v1 
kind: ConfigMap
metadata:
  name: {{ include "otel-agent-chart.fullname" . }}-daemonset-config
data:
  otel-collector-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
          http:
      k8s_cluster:
        auth_type: serviceAccount
        node_conditions_to_report:
          - Ready 
        collection_interval: 1m
        metrics: 
          k8s.container.cpu_request: 
            enabled: false
          k8s.container.cpu_limit:
            enabled: false
          k8s.container.memory_request:
            enabled: false
          k8s.container.memory_limit:
            enabled: false
          k8s.container.storage_request:
            enabled: false
          k8s.container.storage_limit:
            enabled: false
          k8s.container.ephemeralstorage_request:
            enabled: false
          k8s.container.ephemeralstorage_limit:
            enabled: false
          k8s.container.restarts:
            enabled: false
          k8s.container.ready:
            enabled: false
          k8s.pod.phase:
            enabled: false
          k8s.pod.status_reason:
            enabled: false
          k8s.deployment.desired:
            enabled: false
          k8s.deployment.available:
            enabled: false
          k8s.cronjob.active_jobs:
            enabled: false
          k8s.daemonset.current_scheduled_nodes:
            enabled: false
          k8s.daemonset.desired_scheduled_nodes:
            enabled: false
          k8s.daemonset.misscheduled_nodes:
            enabled: false
          k8s.daemonset.ready_nodes:
            enabled: false
          k8s.hpa.max_replicas:
            enabled: false
          k8s.hpa.min_replicas:
            enabled: false
          k8s.hpa.current_replicas:
            enabled: false
          k8s.hpa.desired_replicas:
            enabled: false
          k8s.job.active_pods:
            enabled: false
          k8s.job.desired_successful_pods:
            enabled: false
          k8s.job.failed_pods:
            enabled: false
          k8s.job.max_parallel_pods:
            enabled: false
          k8s.job.successful_pods:
            enabled: false
          k8s.namespace.phase:
            enabled: false
          k8s.replicaset.desired:
            enabled: false
          k8s.replicaset.available:
            enabled: false
          k8s.replication_controller.desired:
            enabled: false
          k8s.replication_controller.available:
            enabled: false
          k8s.resource_quota.hard_limit:
            enabled: false
          k8s.resource_quota.used:
            enabled: false
          k8s.statefulset.desired_pods:
            enabled: false
          k8s.statefulset.ready_pods:
            enabled: false
          k8s.statefulset.current_pods:
            enabled: false
          k8s.statefulset.updated_pods:
            enabled: false
          k8s.node.condition:
            enabled: false
        resource_attributes:
            k8s.namespace.uid:
              enabled: false
            k8s.namespace.name:
              enabled: false
            k8s.node.uid:
              enabled: false
            k8s.node.name:
              enabled: false
            container.id:
              enabled: false
            container.image.name:
              enabled: false
            container.image.tag:
              enabled: false
            k8s.container.name:
              enabled: false
            k8s.pod.name:
              enabled: false
            k8s.pod.uid:
              enabled: false
            k8s.pod.qos_class:
              enabled: false
            k8s.replicaset.name:
              enabled: false
            k8s.replicaset.uid:
              enabled: false
            k8s.replicationcontroller.name:
              enabled: false
            k8s.replicationcontroller.uid:
              enabled: false
            k8s.resourcequota.uid:
              enabled: false
            k8s.resourcequota.name:
              enabled: false
            k8s.statefulset.uid:
              enabled: false
            k8s.statefulset.name:
              enabled: false
            k8s.deployment.uid:
              enabled: false
            k8s.deployment.name:
              enabled: false
            k8s.cronjob.uid:
              enabled: false
            k8s.cronjob.name:
              enabled: false
            k8s.daemonset.name:
              enabled: false
            k8s.daemonset.uid:
              enabled: false
            k8s.hpa.uid:
              enabled: false
            k8s.hpa.name:
              enabled: false
            k8s.job.name:
              enabled: false
            k8s.job.uid:
              enabled: false
      hostmetrics:  
        collection_interval: 20s
        scrapers:
          cpu:
            metrics:
              system.cpu.time:
                enabled: false
              system.cpu.utilization:
                enabled: true
          load:
          memory:
            metrics:
              system.memory.utilization:
                enabled: true
          paging:
            metrics:
              system.paging.utilization:
                enabled: false
              system.paging.faults:
                enabled: false
          filesystem:
            metrics:
              system.filesystem.utilization:
                enabled: true
          disk:
            metrics:
              system.disk.merged:
                enabled: false
              system.disk.pending_operations:
                enabled: false
              system.disk.weighted_io_time:
                enabled: false
          network:
            metrics:
              system.network.connections:
                enabled: false
          processes:
          process:
            metrics:
              process.cpu.utilization:
                enabled: true
              process.cpu.time:
                enabled: false
      kubeletstats:
        collection_interval: 20s
        auth_type: "serviceAccount"
        endpoint: "${K8S_NODE_NAME}:10250"
        insecure_skip_verify: true
        metrics: 
          k8s.container.cpu_limit_utilization:
            enabled: true 
      prometheus:
        config:
          scrape_configs:
            - job_name: cadvisor
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              kubernetes_sd_configs:
                - role: node
              relabel_configs:
                - replacement: kubernetes.default.svc.cluster.local:443
                  target_label: __address__
                - regex: (.+)
                  replacement: /api/v1/nodes/$${1}/proxy/metrics/cadvisor
                  source_labels:
                    - __meta_kubernetes_node_name
                  target_label: __metrics_path__
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: false
                server_name: kubernetes
            - job_name: kubelet
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              kubernetes_sd_configs:
                - role: node
              relabel_configs:
                - replacement: kubernetes.default.svc.cluster.local:443
                  target_label: __address__
                - regex: (.+)
                  replacement: /api/v1/nodes/$${1}/proxy/metrics
                  source_labels:
                    - __meta_kubernetes_node_name
                  target_label: __metrics_path__
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: false
                server_name: kubernetes
            - job_name: kube-state-metrics
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - action: keep
                  regex: kube-state-metrics
                  source_labels:
                    - __meta_kubernetes_pod_label_app_kubernetes_io_name
            - job_name: apiserver
              kubernetes_sd_configs:
                - role: endpoints
                  namespaces:
                    names:
                      - default
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
                  action: keep
                  regex: kubernetes;https
                - action: replace
                  source_labels:
                  - __meta_kubernetes_namespace
                  target_label: Namespace
                - action: replace
                  source_labels:
                  - __meta_kubernetes_service_name
                  target_label: Service
            # node_exporter job not needed, but leaving configuration in incase users want to enable it
            # - job_name: node_exporter
            #   kubernetes_sd_configs:
            #     - role: pod
            #   relabel_configs:
            #     - action: keep
            #       regex: prometheus-node-exporter.*
            #       source_labels:
            #         - __meta_kubernetes_pod_label_app_kubernetes_io_name
            #     - action: replace
            #       source_labels:
            #         - __meta_kubernetes_pod_node_name
            #       target_label: instance
            #     - action: replace
            #       source_labels:
            #         - __meta_kubernetes_namespace
            #       target_label: namespace
      filelog:
        include:
          - /var/log/pods/*/*/*.log
          - /var/log/*/*
          - /var/log/*
          - /var/log/alternatives.log
          - /var/log/cloud-init.log
          - /var/log/auth.log
          - /var/log/dpkg.log
          - /var/log/syslog
          - /var/log/messages
          - /var/log/secure
          - /var/log/yum.log
          - /var/log/alternatives.log
        exclude:
          # Exclude logs from all containers named otel-agent-chart and otelcontribcol
          - /var/log/pods/*/otel-agent-chart/*.log
          - /var/log/pods/*/otelcontribcol/*.log
          - /var/log/pods/*/konnectivity-agent/*.log
          # - /var/log/pods/*/containers/*-exec.log
        start_at: beginning
        include_file_path: true
        include_file_name: true

    processors:
      transform/truncate:
        log_statements:
          - context: log
            statements:
              - truncate_all(attributes, 4095)
              - truncate_all(resource.attributes, 4095)

      metricstransform:
        transforms:
          - include: k8s.node.condition_ready 
            action: update
            new_name: k8s.cluster.info 

      # remove system.cpu metrics for states
      filter/exclude_cpu_utilization:
        metrics:
          datapoint:
            - 'metric.name == "system.cpu.utilization" and attributes["state"] == "interrupt"'
            - 'metric.name == "system.cpu.utilization" and attributes["state"] == "nice"'
            - 'metric.name == "system.cpu.utilization" and attributes["state"] == "softirq"'
      filter/exclude_memory_utilization:
        metrics:
          datapoint:
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "slab_unreclaimable"'
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "inactive"'
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "cached"'
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "buffered"'
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "slab_reclaimable"'
      filter/exclude_memory_usage:
        metrics:
          datapoint:
            - 'metric.name == "system.memory.usage" and attributes["state"] == "slab_unreclaimable"'
            - 'metric.name == "system.memory.usage" and attributes["state"] == "inactive"'
      filter/exclude_filesystem_utilization:
        metrics:
          datapoint:
            - 'metric.name == "system.filesystem.utilization" and attributes["type"] == "squashfs"'
      filter/exclude_filesystem_usage:
        metrics:
          datapoint:
            - 'metric.name == "system.filesystem.usage" and attributes["type"] == "squashfs"'
            - 'metric.name == "system.filesystem.usage" and attributes["state"] == "reserved"'
      filter/exclude_filesystem_inodes_usage:
        metrics:
          datapoint:
            - 'metric.name == "system.filesystem.inodes.usage" and attributes["type"] == "squashfs"'
            - 'metric.name == "system.filesystem.inodes.usage" and attributes["state"] == "reserved"'
      filter/exclude_system_disk:
        metrics:
          datapoint:
            - 'metric.name == "system.disk.operations" and IsMatch(attributes["device"], "^loop.*") == true'
            - 'metric.name == "system.disk.merged" and IsMatch(attributes["device"], "^loop.*") == true'
            - 'metric.name == "system.disk.io" and IsMatch(attributes["device"], "^loop.*") == true'
            - 'metric.name == "system.disk.io_time" and IsMatch(attributes["device"], "^loop.*") == true'
            - 'metric.name == "system.disk.operation_time" and IsMatch(attributes["device"], "^loop.*") == true'
      filter/exclude_system_paging:
        metrics:
          datapoint:
            - 'metric.name == "system.paging.usage" and attributes["state"] == "cached"'
            - 'metric.name == "system.paging.operations" and attributes["type"] == "cached"'
      filter/exclude_network:
        metrics:
          datapoint:
            - 'IsMatch(metric.name, "^system.network.*") == true and attributes["device"] == "lo"'

      experimental_metricsgeneration:
        rules:
          - name: container_fs_usage_percentage
            type: calculate
            metric1: container_fs_usage_bytes
            metric2: container_fs_limit_bytes
            operation: divide
          - name: kube_deployment_pods_missing
            type: calculate
            metric1: kube_deployment_spec_replicas
            metric2: kube_deployment_status_replicas
            operation: subtract
          - name: kube_statefulset_pods_missing
            type: calculate
            metric1: kube_statefulset_replicas
            metric2: kube_statefulset_status_replicas
            operation: subtract
          - name: kube_daemonset_pods_missing
            type: calculate
            metric1: kube_daemonset_status_desired_number_scheduled
            metric2: kube_daemonset_status_current_number_scheduled
            operation: subtract

      attributes/exclude_system_paging:
        include:
          match_type: strict
          metric_names:
            - system.paging.operations
        actions:
          - key: type
            action: delete

      resource:
        attributes:
          - key: host.id
            from_attribute: host.name
            action: upsert
          # UPSERT ONLY IF CLUSTER NAME NOT FONUD???
          - key: k8s.cluster.name
            action: upsert
            value: {{ .Values.cluster.name }}
          - key: newrelicOnly
            action: upsert
            value: 'true'
          - key: service.name
            action: delete

      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          node_from_env_var: KUBE_NODE_NAME
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            # - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
        pod_association:
          - sources: 
            - from: resource_attribute
              name: k8s.pod.uid

      batch:

    exporters:
      otlp:
        endpoint: "otel-gateway:4317"
        tls:
          insecure: true
      logging:
        verbosity: detailed

    service:
      telemetry:
        logs:
          level: "debug"
      pipelines:
        metrics:
          receivers: [otlp, k8s_cluster, hostmetrics, kubeletstats, prometheus]
          processors:
            - metricstransform
            - experimental_metricsgeneration
            - filter/exclude_cpu_utilization
            - filter/exclude_memory_utilization
            - filter/exclude_memory_usage
            - filter/exclude_filesystem_utilization
            - filter/exclude_filesystem_usage
            - filter/exclude_filesystem_inodes_usage
            - filter/exclude_system_disk
            - filter/exclude_system_paging
            - filter/exclude_network
            - attributes/exclude_system_paging
            - resource
            - k8sattributes
            - batch
          exporters: [otlp, logging]
        logs:
          receivers: [otlp, filelog]
          processors: [transform/truncate, resource, k8sattributes, batch]
          exporters: [logging, otlp]